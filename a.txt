
for docker run the command of docker file of postgresql database

This creates a PostgreSQL container with username postgres and 
password mysecretpassword, listening on port 5432. 


  code  ------ docker run --name some-postgres -e POSTGRES_PASSWORD=mysecretpassword -p 5432:5432 
-d postgres ----------

--- dependencies 

pip install Flask Flask-SQLAlchemy psycopg2-binary
#

Flask==2.3.2
Flask-SQLAlchemy==3.1.1
psycopg2-binary==2.9.9
gunicorn==21.2.0

# Use an official Python runtime as a parent image
FROM python:3.9-slim-buster

# Set the working directory in the container
WORKDIR /app

# Install system dependencies required by psycopg2
# This ensures that psycopg2 can compile properly
RUN apt-get update && apt-get install -y \
    gcc \
    libpq-dev \
    netcat-traditional \
    && rm -rf /var/lib/apt/lists/*

# Copy the requirements file into the container at /app
COPY requirements.txt .

# Install any needed packages specified in requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

# Copy the rest of the application code into the container at /app
COPY . .

# Expose port 5000 (where Gunicorn will run)
EXPOSE 5000

# Command to run the application using Gunicorn
# Using 0.0.0.0 to bind to all available network interfaces
# The `wait-for-it.sh` script (see docker-compose below) ensures DB is ready before starting Gunicorn
CMD ["gunicorn", "--bind", "0.0.0.0:5000", "app:app"]



docker-compose.yml

Create a file named docker-compose.yml in the same directory. This file will define and run both your Flask app and a PostgreSQL database as separate services.

YAML

version: '3.8'

services:
  # Flask Application Service
  web:
    build: . # Build the Docker image from the current directory (where Dockerfile is)
    ports:
      - "5000:5000" # Map host port 5000 to container port 5000
    environment:
      # These environment variables will be passed into your Flask app container
      # Ensure these match the values in your app.py if not using os.environ.get defaults
      DB_USER: postgres
      DB_PASSWORD: mysecretpassword
      DB_HOST: db # This matches the service name of the database container
      DB_PORT: 5432
      DB_NAME: my_app_db
    # Depends on the 'db' service to start first.
    # We'll use a custom script to wait for the database to be truly ready.
    depends_on:
      db:
        condition: service_healthy
    # Command to run (overrides CMD in Dockerfile for this service if needed)
    # Using a script to wait for the DB to be ready before starting Gunicorn
    command: ["/usr/bin/env", "bash", "-c", "python -c 'import sys; from urllib.parse import urlparse; url = urlparse(\"postgresql://$$DB_USER:$$DB_PASSWORD@$$DB_HOST:$$DB_PORT/$$DB_NAME\"); print(f\"host={url.hostname} port={url.port} dbname={url.path[1:]} user={url.username} password={url.password}\")' | xargs -L 1 -J % pg_isready -h % -p % -U % -d % && gunicorn --bind 0.0.0.0:5000 app:app"]


  # PostgreSQL Database Service
  db:
    image: postgres:13 # Use a specific PostgreSQL version
    restart: always # Always restart if it crashes
    environment:
      POSTGRES_DB: my_app_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: mysecretpassword
    volumes:
      # Persist database data to a named volume
      - db_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d my_app_db"]
      interval: 5s
      timeout: 5s
      retries: 5

volumes:
  db_data: # Define the named volume for data persistence